
@inproceedings{hehardness2025,
  title={On the Hardness of Conditional Independence Testing In Practice},
  author={He, Zheng and Pogodin, Roman and Li, Yazhe and Deka, Namrata and Gretton, Arthur and Sutherland, Danica J.},
  booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems, NeurIPS},
  year={2025},
  selected={true},
  abstract={Tests of conditional independence (CI) underpin a number of important problems in machine learning and statistics, from causal discovery to evaluation of predictor fairness and out-of-distribution robustness. Shah and Peters (2020) showed that, contrary to the unconditional case, no universally finite-sample valid test can ever achieve nontrivial power. While informative, this result (based on "hiding" dependence) does not seem to explain the frequent practical failures observed with popular CI tests. We investigate the Kernel-based Conditional Independence (KCI) test - of which we show the Generalized Covariance Measure underlying many recent tests is nearly a special case - and identify the major factors underlying its practical behavior. We highlight the key role of errors in the conditional mean embedding estimate for the Type-I error, while pointing out the importance of selecting an appropriate conditioning kernel (not recognized in previous work) as being necessary for good test power but also tending to inflate Type-I error.},
  code={https://github.com/he-zh/kci-hardness},
  poster={kci_hardness_nips2025_poster.pdf},
  arxiv={2512.14000},
  note={Selected for spotlight presentation.},
  blog={/blog/2025/ci-hardness/}
}

@article{hu2025efficient,
  title={Efficient kernelized bandit algorithms via exploration distributions},
  author={Hu, Bingshan and He, Zheng and Sutherland, Danica J.},
  journal={arXiv preprint arXiv:2506.10091},
  year={2025},
  selected={false},
  abstract={We consider a kernelized bandit problem with a compact arm set  and a fixed but unknown reward function  with a finite norm in some Reproducing Kernel Hilbert Space (RKHS). We propose a class of computationally efficient kernelized bandit algorithms, which we call GP-Generic, based on a novel concept: exploration distributions. This class of algorithms includes Upper Confidence Bound-based approaches as a special case, but also allows for a variety of randomized algorithms. With careful choice of exploration distribution, our proposed generic algorithm realizes a wide range of concrete algorithms that achieve  regret bounds, where  characterizes the RKHS complexity. This matches known results for UCB- and Thompson Sampling-based algorithms; we also show that in practice, randomization can yield better practical results.},
  arxiv={2506.10091},
  }
 
 

@inproceedings{he2022sparse,
  title={Sparse double descent: Where network pruning aggravates overfitting},
  author={He, Zheng and Xie, Zeke and Zhu, Quanzhi and Qin, Zengchang},
  booktitle={International Conference on Machine Learning, ICML},
  pages={8635--8659},
  year={2022},
  organization={PMLR},
  abstract={People usually believe that network pruning not only reduces the computational cost of deep networks, but also prevents overfitting by decreasing model capacity. However, our work surprisingly discovers that network pruning sometimes even aggravates overfitting. We report an unexpected sparse double descent phenomenon that, as we increase model sparsity via network pruning, test performance first gets worse (due to overfitting), then gets better (due to relieved overfitting), and gets worse at last (due to forgetting useful information). While recent studies focused on the deep double descent with respect to model overparameterization, they failed to recognize that sparsity may also cause double descent. In this paper, we have three main contributions. First, we report the novel sparse double descent phenomenon through extensive experiments. Second, for this phenomenon, we propose a novel learning distance interpretation that the curve of l2 learning distance of sparse models (from initialized parameters to final parameters) may correlate with the sparse double descent curve well and reflect generalization better than minima flatness. Third, in the context of sparse double descent, a winning ticket in the lottery ticket hypothesis surprisingly may not always win.},
  arxiv={2206.08684},
  poster={sparsedd_icml2022_poster.pdf},
  code={https://github.com/he-zh/sparse-double-descent},
  selected={true},
  blog={/blog/2022/sparsedd/}
}

@inproceedings{zhou2021random,
  title={Random Neural Graph Generation with Structure Evolution},
  author={Zhou, Yuguang and He, Zheng and Wan, Tao and Qin, Zengchang},
  booktitle={Neural Information Processing: 28th International Conference, ICONIP},
  pages={87--98},
  year={2021},
  organization={Springer International Publishing},
  abstract={In deep learning research, typical neural network models are multi-layered architectures, and weights are tuned while optimizing a carefully designed loss function. In recent years, studies of randomized neural networks have been extended towards deep architectures, opening a new research direction to the design of deep learning models. However, how the structure of the network can influence the model performance still remains unclear. In this paper, we move a further step to investigate the relation between network topology and performance via a structure evolution algorithm. Experimental results show that the graph would evolve towards a more small-world topology at the beginning of the training session along with gaining accuracy, and would also evolve towards a structure with more scale-free property in the following periods. These conclusions could help explain the effectiveness of the randomly connected networks, as well as give us insights in new possibilities of network architecture design.},
  html={https://link.springer.com/chapter/10.1007/978-3-030-92270-2_8},
  selected={false}
}



@inproceedings{xie2025learning,
  title={Learning from Ambiguous Data with Hard Labels},
  author={Xie, Zeke and He, Zheng and Lu, Nan and Bai, Lichen and Li, Bao and Yang, Shuo and Sun, Mingming and Li, Ping},
  booktitle={ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2025},
  organization={IEEE},
  selected={false},
  abstract={Real-world data often contains intrinsic ambiguity
that the common single-hard-label annotation paradigm ignores.
Standard training using ambiguous data with these hard labels
may produce overly confident models and thus leading to poor
generalization. In this paper, we propose a novel framework
called Quantized Label Learning (QLL) to alleviate this issue.
First, we formulate QLL as learning from (very) ambiguous data
with hard labels: ideally, each ambiguous instance should be
associated with a ground-truth soft-label distribution describing
its corresponding probabilistic weight in each class, however,
this is usually not accessible; in practice, we can only observe
a quantized label, i.e., a hard label sampled (quantized) from
the corresponding ground-truth soft-label distribution, of each
instance, which can be seen as a biased approximation of
the ground-truth soft-label. Second, we propose a Class-wise
Positive-Unlabeled (CPU) risk estimator that allows us to train
accurate classifiers from only ambiguous data with quantized
labels. Third, to simulate ambiguous datasets with quantized
labels in the real world, we design a mixing-based ambiguous
data generation procedure for empirical evaluation. Experiments
demonstrate that our CPU method can significantly improve
model generalization performance and outperform the baselines.},
  arxiv={2501.01844},
}

