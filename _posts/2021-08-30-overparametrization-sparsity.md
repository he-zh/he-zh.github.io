---
layout: post
title:  Overparameterization and sparsity
date:   2021-08-30
description: a review on recent paper about overparameterization and sparsity
tags: survey paper-digest slides sparse overparameterization
categories: research
related_posts: true
related_publications: he2022sparse
---

It is a mystery how overparameterized models behave and why. It is especially intriguing why overparameterized models can generalize well despite the excessive capacity, and why highly sparse neural networks can still achieve comparable performance to the dense networks (as suggested in the [lottery ticket hypothesis](https://arxiv.org/abs/1803.03635)). 

Over the past few months, I have been intrigued by the possible relationship between model generalization and sparsity. The slides below give a brief review of several related works and the questions that I cared about. Luckily I am able to answer a few of them with my own research now (see [sparse double descent](https://he-zh.github.io/_posts/2022-07-Sparse_double_descent/)).


<object data="/assets/pdf/ZhengHe_overparametrized_neural_networks.pdf" width="100%" height="500px">
    <p>Unable to display PDF file. <a href="/assets/pdf/ZhengHe_overparametrized_neural_networks.pdf">Download</a> instead.</p>
</object>